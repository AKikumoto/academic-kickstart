@article{Kikumoto2019-xz,
 abstract = {In competitive situations, winning depends on selecting actions
that surprise the opponent. Such unpredictable action can be
generated based on representations of the opponent's strategy and
choice history (model-based counter-prediction) or by choosing
actions in a memory-free, stochastic manner. Across five
different experiments using a variant of a matching-pennies game
with simulated and human opponents we found that people toggle
between these two strategies, using model-based selection when
recent wins signal the appropriateness of the current model, but
reverting to stochastic selection following losses. Also, after
wins, feedback-related, mid-frontal EEG activity reflected
information about the opponent's global and local strategy, and
predicted upcoming choices. After losses, this activity was
nearly absent-indicating that the internal model is suppressed
after negative feedback. We suggest that the mixed-strategy
approach allows negotiating two conflicting goals: (1) exploiting
the opponent's deviations from randomness while (2) remaining
unpredictable for the opponent.},
 author = {Kikumoto, Atsushi and Mayr, Ulrich},
 journal = {Elife},
 keywords = {human; neuroscience;MyPapers},
 language = {en},
 month = {October},
 title = {Balancing model-based and memory-free action selection under
competitive pressure},
 volume = {8},
 year = {2019}
}

